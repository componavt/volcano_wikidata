{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/volcano_wikidata/blob/main/src/bipartite_graph_freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Bipartite Clustering of Volcanoes and Earthquakes 🌋🌍\n",
        "\n",
        "This notebook implements a custom bipartite clustering algorithm to study spatial relationships between volcanoes and earthquakes.\n",
        "It treats volcanoes and earthquakes as two different sets of nodes and forms clusters based only on volcano–earthquake proximity, not between volcanoes or between earthquakes.\n",
        "Key Features:\n",
        "   \n",
        "    📈 Dynamically tracks cluster structure using union–find (disjoint-set).\n",
        "\n",
        "    🌀 At each clustering step (by increasing distance), it records:\n",
        "\n",
        "        Total number of clusters\n",
        "\n",
        "        Size of the largest cluster\n",
        "\n",
        "        Average cluster size\n",
        "\n",
        "        Diameter (max distance) within the largest cluster\n",
        "\n",
        "        Number of clusters of 3 types:\n",
        "\n",
        "            Only volcanoes\n",
        "\n",
        "            Only earthquakes\n",
        "\n",
        "            Mixed volcano–earthquake clusters\n",
        "\n",
        "Output:\n",
        "\n",
        "    📊 Two graphs show cluster evolution:\n",
        "\n",
        "        Main metrics (group count, size, diameter)\n",
        "\n",
        "        Composition breakdown (volcano-only, earthquake-only, mixed)\n",
        "\n",
        "    🖨️ Console progress with % completion and current distance.\n",
        "\n",
        "🔍 Двудольная кластеризация вулканов и землетрясений 🌋📊\n",
        "\n",
        "Этот код реализует специальный алгоритм кластеризации, который объединяет вулканы и землетрясения в группы, учитывая только пары между вулканом и землетрясением.\n",
        "Особенности:\n",
        "\n",
        "    📐 Использует геодезическое расстояние между координатами (из Wikidata).\n",
        "\n",
        "    🚫 Игнорирует пары, расстояние между которыми превышает MAX_DISTANCE_KM.\n",
        "\n",
        "    🔢 Для каждого землетрясения учитываются только K ближайших вулканов (K_NEAREST).\n",
        "\n",
        "    🔁 Кластеры формируются с помощью структуры непересекающихся множеств (union–find).\n",
        "\n",
        "    📊 На каждом шаге кластеризации (по возрастанию расстояния) сохраняется:\n",
        "\n",
        "        Общее количество кластеров\n",
        "\n",
        "        Размер наибольшего кластера\n",
        "\n",
        "        Средний размер кластеров\n",
        "\n",
        "        Диаметр наибольшего кластера\n",
        "\n",
        "        Количество кластеров следующих типов:\n",
        "\n",
        "            Только вулканы\n",
        "\n",
        "            Только землетрясения\n",
        "\n",
        "            Смешанные (вулканы + землетрясения)\n",
        "\n",
        "Результаты:\n",
        "\n",
        "    📈 Построены два графика:\n",
        "\n",
        "        Эволюция метрик кластеров\n",
        "\n",
        "        Состав кластеров по типу\n",
        "\n",
        "    ⏳ В консоли отображается ход выполнения и текущая итерация."
      ],
      "metadata": {
        "id": "ugzDdnAHuquC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input parameters\n",
        "LANGUAGE = 'ru'  # 'en' or 'ru'\n",
        "\n",
        "f_volcano = \"volcanoes_2023.csv\"\n",
        "f_earthquake = \"earthquakes_2023.csv\"\n",
        "\n",
        "# --- Distance thresholds to explore ---\n",
        "# dist_max = 100  # maximum distance (km) between volcano and earthquake to draw a line\n",
        "\n",
        "# distances_max_list = range(10, 250, 10)  # Test thresholds from 10 km to 250 km\n",
        "# distances_max_list = range(30, 150, 10)\n",
        "distances_max_list = list(range(30, 80, 10)) + list(range(80, 100, 1)) + list(range(100, 150, 10)) # slow real\n",
        "# distances_max_list = list(range(30, 80, 20)) + list(range(80, 100, 5)) + list(range(100, 150, 20)) # fast\n",
        "\n",
        "# шаг 10 для диапазона 80-170, но шаг 2 для диапазона 120-130, чтобы увидеть на графике локальный изгиб\n",
        "# [80, 90, 100, 110, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 140, 150, 160]\n",
        "#distances_max_list = list(range(80, 120, 10)) + list(range(120, 130, 1)) + list(range(130, 170, 10))\n",
        "\n",
        "# fast: шаг 40 для диапазона 80-170, но шаг 5 для диапазона 120-130, чтобы увидеть на графике локальный изгиб\n",
        "# [80, 120, 127, 128, 130, 170]\n",
        "#distances_max_list = list(range(80, 121, 40)) + [125] + list(range(127, 129, 1)) + list(range(130, 171, 40))\n",
        "#distances_max_list = list(range(80, 121, 40))          + list(range(127, 129, 1)) + list(range(130, 171, 40))\n",
        "\n",
        "print(distances_max_list)"
      ],
      "metadata": {
        "id": "OVPvGgAy4Qlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c62f985-ab83-410d-b825-1391e25bd687"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 40, 50, 60, 70, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 110, 120, 130, 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from scipy.spatial import KDTree\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import host_subplot\n",
        "import mpl_toolkits.axisartist as AA\n",
        "import folium\n",
        "# import pprint # Pretty Print for objects\n",
        "\n",
        "\n",
        "# Download CSV files from GitHub\n",
        "!wget https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/$f_volcano\n",
        "!wget https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/$f_earthquake\n",
        "\n",
        "!head -n 3 $f_volcano\n",
        "!head -n 3 $f_earthquake"
      ],
      "metadata": {
        "id": "GNYfOTSXfz13",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f277e98a-61c1-4adb-803f-9c56021cb807"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-02 07:51:38--  https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/volcanoes_2023.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76165 (74K) [text/plain]\n",
            "Saving to: ‘volcanoes_2023.csv’\n",
            "\n",
            "volcanoes_2023.csv  100%[===================>]  74.38K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-02 07:51:39 (3.11 MB/s) - ‘volcanoes_2023.csv’ saved [76165/76165]\n",
            "\n",
            "--2025-05-02 07:51:39--  https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/earthquakes_2023.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124602 (122K) [text/plain]\n",
            "Saving to: ‘earthquakes_2023.csv’\n",
            "\n",
            "earthquakes_2023.cs 100%[===================>] 121.68K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-05-02 07:51:39 (4.43 MB/s) - ‘earthquakes_2023.csv’ saved [124602/124602]\n",
            "\n",
            "volcanoLabel;location\n",
            "Puy Pariou;Point(2.971484 45.796824)\n",
            "Вануа-Лава;Point(167.466666666 -13.8)\n",
            "earthquakeLabel;location\n",
            "1975 Lice earthquake;Point(40.723 38.474)\n",
            "2011 Hindukush earthquake;Point(71.102 36.502)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📏 Computing the Maximum Diameter of a Group"
      ],
      "metadata": {
        "id": "1Q9gcPPHbK6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.distance import geodesic\n",
        "\n",
        "def compute_group_diameter(group_coords):\n",
        "    max_distance = 0\n",
        "    n = len(group_coords)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            d = geodesic(group_coords[i], group_coords[j]).km\n",
        "            if d > max_distance:\n",
        "                max_distance = d\n",
        "    return max_distance"
      ],
      "metadata": {
        "id": "YBDpMO6PXBao"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📉 Compresses scale before 120, 📈 stretches 120-130, 📉 compresses after 130."
      ],
      "metadata": {
        "id": "ZnP1jf5WtzIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_x(x, compress_before=0.5, compress_between=2.0, compress_after=0.5):\n",
        "    \"\"\"\n",
        "    Transforms the input distance x with different compression ratios for different intervals.\n",
        "\n",
        "    Parameters:\n",
        "        x (float): Input distance value to be transformed\n",
        "        compress_before (float): Compression factor for x < 120 (default: 0.5)\n",
        "        compress_between (float): Compression/stretch factor for 120 <= x <= 130 (default: 2.0)\n",
        "        compress_after (float): Compression factor for x > 130 (default: 0.5)\n",
        "\n",
        "    Returns:\n",
        "        float: Transformed value of x according to the specified compression rules\n",
        "\n",
        "    Behavior:\n",
        "        - For x < 120: applies compress_before multiplier (compression if < 1.0)\n",
        "        - For 120-130: applies compress_between multiplier (stretches if > 1.0)\n",
        "        - For x > 130: applies compress_after multiplier (compression if < 1.0)\n",
        "    \"\"\"\n",
        "    if x < 120:\n",
        "        return x * compress_before  # Compress region before 120 km\n",
        "    elif 120 <= x <= 130:\n",
        "        return 120 * compress_before + (x - 120) * compress_between  # Transform 120-130 km region\n",
        "    else:\n",
        "        return (120 * compress_before + 10 * compress_between) + (x - 130) * compress_after  # Compress region after 130 km"
      ],
      "metadata": {
        "id": "wJ8ZrPHItSt6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CSFrFaVftfuV",
        "outputId": "b467d15a-a7c1-4210-f0c8-1aaec674e53a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0/4553] —   0.0% complete — dist =   1.16 km, clusters = 3653, diameter = 1.2 km\n",
            "[  100/4553] —   2.2% complete — dist =  16.89 km, clusters = 3600, diameter = 11.3 km\n",
            "[  300/4553] —   6.6% complete — dist =  34.38 km, clusters = 3534, diameter = 31.6 km\n",
            "[  400/4553] —   8.8% complete — dist =  41.88 km, clusters = 3515, diameter = 31.6 km\n",
            "[ 1300/4553] —  28.6% complete — dist =  96.90 km, clusters = 3350, diameter = 89.8 km\n",
            "[ 1400/4553] —  30.7% complete — dist = 102.12 km, clusters = 3340, diameter = 89.8 km\n",
            "[ 2900/4553] —  63.7% complete — dist = 186.27 km, clusters = 3182, diameter = 89.8 km\n",
            "[ 3100/4553] —  68.1% complete — dist = 198.97 km, clusters = 3165, diameter = 89.8 km\n",
            "[ 3200/4553] —  70.3% complete — dist = 205.81 km, clusters = 3155, diameter = 89.8 km\n"
          ]
        }
      ],
      "source": [
        "# === BIPARTITE CLUSTERING: VOLCANO–EARTHQUAKE GRAPH WITH FREEZING MIXED GROUPS ===\n",
        "\n",
        "# --- PARAMETERS ---\n",
        "MAX_DISTANCE_KM = 300  # discard volcano–earthquake pairs farther than this\n",
        "K_NEAREST = 5  # for each earthquake, consider only k nearest volcanoes (to reduce number of pairs)\n",
        "KM_SCALING_FACTOR = 1000  # to scale diameter from meters to kilometers in plot\n",
        "MIN_DIAMETER_FOR_MAP = 100  # Only show mixed clusters on map if diameter > this value (km)\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "\n",
        "# --- Load volcano and earthquake coordinates ---\n",
        "def parse_coords(coord_string):\n",
        "    lon, lat = map(float, coord_string.replace(\"Point(\", \"\").replace(\")\", \"\").split())\n",
        "    return (lat, lon)\n",
        "\n",
        "volcano_coords = []\n",
        "earthquake_coords = []\n",
        "\n",
        "with open(\"volcanoes_2023.csv\", encoding='utf-8', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter=\";\")\n",
        "    for row in reader:\n",
        "        volcano_coords.append(parse_coords(row['location']))\n",
        "\n",
        "with open(\"earthquakes_2023.csv\", encoding='utf-8', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter=\";\")\n",
        "    for row in reader:\n",
        "        earthquake_coords.append(parse_coords(row['location']))\n",
        "\n",
        "# --- Build bipartite edge list with limited k nearest volcanoes for each earthquake ---\n",
        "pairs = []\n",
        "for ei, e_coord in enumerate(earthquake_coords):\n",
        "    distances = []\n",
        "    for vi, v_coord in enumerate(volcano_coords):\n",
        "        dist = geodesic(e_coord, v_coord).km\n",
        "        if dist <= MAX_DISTANCE_KM:\n",
        "            distances.append((dist, vi, ei))\n",
        "    distances.sort()\n",
        "    pairs.extend(distances[:K_NEAREST])\n",
        "\n",
        "pairs.sort()  # sort by increasing distance\n",
        "\n",
        "# --- Clustering loop ---\n",
        "volcano_count = len(volcano_coords)\n",
        "earthquake_count = len(earthquake_coords)\n",
        "total_points = volcano_count + earthquake_count\n",
        "\n",
        "parent = list(range(total_points))\n",
        "frozen = [False] * total_points  # marks if the cluster is frozen\n",
        "\n",
        "# Find the root of a node in the disjoint-set structure (with path compression)\n",
        "def find(x):\n",
        "    \"\"\"Returns the representative/root of the set containing x.\"\"\"\n",
        "    while parent[x] != x:\n",
        "        parent[x] = parent[parent[x]]\n",
        "        x = parent[x]\n",
        "    return x\n",
        "\n",
        "# Union two sets in the disjoint-set structure\n",
        "# Prevent merging if either cluster is frozen\n",
        "def union(x, y):\n",
        "    \"\"\"Merges the sets containing x and y unless frozen.\"\"\"\n",
        "    xroot, yroot = find(x), find(y)\n",
        "    if xroot != yroot and not (frozen[xroot] or frozen[yroot]):\n",
        "        parent[yroot] = xroot\n",
        "\n",
        "# --- Track metrics ---\n",
        "step_distances = []\n",
        "group_counts = []\n",
        "avg_sizes = []\n",
        "largest_sizes = []\n",
        "largest_diameters = []\n",
        "volcano_only = []\n",
        "earthquake_only = []\n",
        "mixed_groups = []\n",
        "mixed_clusters_for_map = []\n",
        "\n",
        "all_coords = volcano_coords + earthquake_coords\n",
        "\n",
        "for step, (dist, vi, ei) in enumerate(pairs):\n",
        "    vi_idx = vi\n",
        "    ei_idx = volcano_count + ei\n",
        "\n",
        "    vi_root = find(vi_idx)\n",
        "    ei_root = find(ei_idx)\n",
        "\n",
        "    if vi_root != ei_root and not (frozen[vi_root] or frozen[ei_root]):\n",
        "        union(vi_idx, ei_idx)\n",
        "\n",
        "        # Recompute clusters\n",
        "        clusters = defaultdict(list)\n",
        "        for idx in range(total_points):\n",
        "            clusters[find(idx)].append(idx)\n",
        "\n",
        "        sizes = [len(c) for c in clusters.values()]\n",
        "        avg_size = np.mean(sizes)\n",
        "        largest_size = np.max(sizes)\n",
        "\n",
        "        # Compute diameter for largest cluster\n",
        "        largest_cluster = max(clusters.values(), key=len)\n",
        "        coords = [all_coords[i] for i in largest_cluster]\n",
        "        max_d = 0\n",
        "        for i in range(len(coords)):\n",
        "            for j in range(i+1, len(coords)):\n",
        "                d = geodesic(coords[i], coords[j]).km\n",
        "                if d > max_d:\n",
        "                    max_d = d\n",
        "\n",
        "        # Group type breakdown + freezing logic\n",
        "        v_only = e_only = mixed = 0\n",
        "        for cluster in clusters.values():\n",
        "            types = {\"volcano\" if i < volcano_count else \"earthquake\" for i in cluster}\n",
        "            root = find(cluster[0])\n",
        "            if types == {\"volcano\"}:\n",
        "                v_only += 1\n",
        "            elif types == {\"earthquake\"}:\n",
        "                e_only += 1\n",
        "            else:\n",
        "                mixed += 1\n",
        "                frozen[root] = True\n",
        "                if max_d > MIN_DIAMETER_FOR_MAP:\n",
        "                    mixed_clusters_for_map.append(cluster)\n",
        "\n",
        "        # Store stats\n",
        "        step_distances.append(dist)\n",
        "        group_counts.append(len(clusters))\n",
        "        avg_sizes.append(avg_size)\n",
        "        largest_sizes.append(largest_size)\n",
        "        largest_diameters.append(max_d)\n",
        "        volcano_only.append(v_only)\n",
        "        earthquake_only.append(e_only)\n",
        "        mixed_groups.append(mixed)\n",
        "\n",
        "        # Print progress\n",
        "        if step % 100 == 0 or step == len(pairs) - 1:\n",
        "            percent = step / len(pairs) * 100\n",
        "            print(f\"[{step:5d}/{len(pairs)}] — {percent:5.1f}% complete — dist = {dist:6.2f} km, clusters = {len(clusters):4d}, diameter = {max_d:.1f} km\")\n",
        "\n",
        "# --- PLOT METRICS ---\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(14,8))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "p1, = ax1.plot(step_distances, group_counts, label=\"Total Groups\", color='blue')\n",
        "p2, = ax1.plot(step_distances, largest_sizes, label=\"Largest Group Size\", color='orange')\n",
        "p3, = ax2.plot(step_distances, avg_sizes, label=\"Avg Group Size\", color='red', linestyle='--')\n",
        "p4, = ax2.plot(step_distances, [x/KM_SCALING_FACTOR for x in largest_diameters], label=\"Largest Diameter (km)\", color='green', linestyle='-.')\n",
        "\n",
        "ax1.set_xlabel(\"Step Distance (km)\", fontsize=14)\n",
        "ax1.set_ylabel(\"Group Count / Size\", fontsize=14)\n",
        "ax2.set_ylabel(\"Avg Size / Diameter\", fontsize=14)\n",
        "\n",
        "lines = [p1, p2, p3, p4]\n",
        "labels = [line.get_label() for line in lines]\n",
        "ax1.legend(lines, labels, loc='upper right')\n",
        "plt.title(\"Bipartite Clustering Metrics (Mixed Groups Frozen)\", fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- SECOND PLOT: group type breakdown ---\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14,6))\n",
        "ax.plot(step_distances, volcano_only, label=\"Volcano-only\", color='red', linestyle='--')\n",
        "ax.plot(step_distances, earthquake_only, label=\"Earthquake-only\", color='black', linestyle='dashed')\n",
        "ax.plot(step_distances, mixed_groups, label=\"Mixed\", color='green', linewidth=2.5)\n",
        "\n",
        "ax.set_xlabel(\"Step Distance (km)\", fontsize=14)\n",
        "ax.set_ylabel(\"Group Count by Type\", fontsize=14)\n",
        "ax.legend(loc='upper right')\n",
        "plt.title(\"Group Type Composition During Bipartite Clustering (with Freezing)\", fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- VISUALIZE FROZEN MIXED CLUSTERS ON MAP ---\n",
        "\n",
        "def compute_center_by_farthest_pair(group_coords):\n",
        "    max_distance = 0\n",
        "    farthest_pair = (0, 0)\n",
        "    n = len(group_coords)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            d = geodesic(group_coords[i], group_coords[j]).km\n",
        "            if d > max_distance:\n",
        "                max_distance = d\n",
        "                farthest_pair = (i, j)\n",
        "    lat1, lon1 = group_coords[farthest_pair[0]]\n",
        "    lat2, lon2 = group_coords[farthest_pair[1]]\n",
        "    center_lat = (lat1 + lat2) / 2\n",
        "    center_lon = (lon1 + lon2) / 2\n",
        "    return (center_lat, center_lon), max_distance\n",
        "\n",
        "m = folium.Map(location=[0, 0], zoom_start=2)\n",
        "\n",
        "for cluster in mixed_clusters_for_map:\n",
        "    coords = [all_coords[i] for i in cluster]\n",
        "    center, diameter = compute_center_by_farthest_pair(coords)\n",
        "    folium.Circle(\n",
        "        location=center,\n",
        "        radius=(diameter / 2) * 1000,  # meters\n",
        "        color=\"green\",\n",
        "        fill=False,\n",
        "        weight=2,\n",
        "        opacity=0.5\n",
        "    ).add_to(m)\n",
        "\n",
        "m.save(\"frozen_mixed_clusters_map.html\")"
      ]
    }
  ]
}