{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/volcano_wikidata/blob/main/src/bipartite_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# todo docs Bipartite clustering"
      ],
      "metadata": {
        "id": "EgJCzbEhsfgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌋+🌎 Group Type Analysis: Volcanoes & Earthquakes\n",
        "\n",
        "This script analyzes clusters (connected components) of volcanoes and earthquakes based on a spatial proximity threshold (`dist_max`). We form **groups** (clusters) where the distance between any two points is below `dist_max`.\n",
        "\n",
        "For each distance, we compute:\n",
        "\n",
        "- 🌋 **Number of volcano-only groups** — groups containing only volcanoes.\n",
        "- 🌎 **Number of earthquake-only groups** — groups containing only earthquakes.\n",
        "- 🌋+🌎 **Number of mixed groups** — groups containing both volcanoes and earthquakes.\n",
        "\n",
        "The goal is to understand the composition of spatial clusters depending on distance.\n",
        "\n",
        "For the program to work, you need two CSV files generated using SPARQL queries: https://w.wiki/AXz7 and https://w.wiki/AY2R"
      ],
      "metadata": {
        "id": "ugzDdnAHuquC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input parameters\n",
        "LANGUAGE = 'ru'  # 'en' or 'ru'\n",
        "\n",
        "f_volcano = \"volcanoes_2023.csv\"\n",
        "f_earthquake = \"earthquakes_2023.csv\"\n",
        "\n",
        "# --- Distance thresholds to explore ---\n",
        "# dist_max = 100  # maximum distance (km) between volcano and earthquake to draw a line\n",
        "\n",
        "# distances_max_list = range(10, 250, 10)  # Test thresholds from 10 km to 250 km\n",
        "# distances_max_list = range(30, 150, 10)\n",
        "distances_max_list = list(range(30, 80, 10)) + list(range(80, 100, 1)) + list(range(100, 150, 10)) # slow real\n",
        "# distances_max_list = list(range(30, 80, 20)) + list(range(80, 100, 5)) + list(range(100, 150, 20)) # fast\n",
        "\n",
        "# шаг 10 для диапазона 80-170, но шаг 2 для диапазона 120-130, чтобы увидеть на графике локальный изгиб\n",
        "# [80, 90, 100, 110, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 140, 150, 160]\n",
        "#distances_max_list = list(range(80, 120, 10)) + list(range(120, 130, 1)) + list(range(130, 170, 10))\n",
        "\n",
        "# fast: шаг 40 для диапазона 80-170, но шаг 5 для диапазона 120-130, чтобы увидеть на графике локальный изгиб\n",
        "# [80, 120, 127, 128, 130, 170]\n",
        "#distances_max_list = list(range(80, 121, 40)) + [125] + list(range(127, 129, 1)) + list(range(130, 171, 40))\n",
        "#distances_max_list = list(range(80, 121, 40))          + list(range(127, 129, 1)) + list(range(130, 171, 40))\n",
        "\n",
        "print(distances_max_list)"
      ],
      "metadata": {
        "id": "OVPvGgAy4Qlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86085d9a-374c-42cb-cdbd-8d86b08a374f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 40, 50, 60, 70, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 110, 120, 130, 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from scipy.spatial import KDTree\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import host_subplot\n",
        "import mpl_toolkits.axisartist as AA\n",
        "import folium\n",
        "# import pprint # Pretty Print for objects\n",
        "\n",
        "\n",
        "# Download CSV files from GitHub\n",
        "!wget https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/$f_volcano\n",
        "!wget https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/$f_earthquake\n",
        "\n",
        "!head -n 3 $f_volcano\n",
        "!head -n 3 $f_earthquake"
      ],
      "metadata": {
        "id": "GNYfOTSXfz13",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405d9308-b000-48aa-80fd-9d36c72ee6dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-01 16:32:49--  https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/volcanoes_2023.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76165 (74K) [text/plain]\n",
            "Saving to: ‘volcanoes_2023.csv’\n",
            "\n",
            "\rvolcanoes_2023.csv    0%[                    ]       0  --.-KB/s               \rvolcanoes_2023.csv  100%[===================>]  74.38K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-01 16:32:49 (3.34 MB/s) - ‘volcanoes_2023.csv’ saved [76165/76165]\n",
            "\n",
            "--2025-05-01 16:32:49--  https://raw.githubusercontent.com/componavt/volcano_wikidata/master/data/earthquakes_2023.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124602 (122K) [text/plain]\n",
            "Saving to: ‘earthquakes_2023.csv’\n",
            "\n",
            "earthquakes_2023.cs 100%[===================>] 121.68K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-01 16:32:49 (4.78 MB/s) - ‘earthquakes_2023.csv’ saved [124602/124602]\n",
            "\n",
            "volcanoLabel;location\n",
            "Puy Pariou;Point(2.971484 45.796824)\n",
            "Вануа-Лава;Point(167.466666666 -13.8)\n",
            "earthquakeLabel;location\n",
            "1975 Lice earthquake;Point(40.723 38.474)\n",
            "2011 Hindukush earthquake;Point(71.102 36.502)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📏 Computing the Maximum Diameter of a Group"
      ],
      "metadata": {
        "id": "1Q9gcPPHbK6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.distance import geodesic\n",
        "\n",
        "def compute_group_diameter(group_coords):\n",
        "    max_distance = 0\n",
        "    n = len(group_coords)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            d = geodesic(group_coords[i], group_coords[j]).km\n",
        "            if d > max_distance:\n",
        "                max_distance = d\n",
        "    return max_distance"
      ],
      "metadata": {
        "id": "YBDpMO6PXBao"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📉 Compresses scale before 120, 📈 stretches 120-130, 📉 compresses after 130."
      ],
      "metadata": {
        "id": "ZnP1jf5WtzIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_x(x, compress_before=0.5, compress_between=2.0, compress_after=0.5):\n",
        "    \"\"\"\n",
        "    Transforms the input distance x with different compression ratios for different intervals.\n",
        "\n",
        "    Parameters:\n",
        "        x (float): Input distance value to be transformed\n",
        "        compress_before (float): Compression factor for x < 120 (default: 0.5)\n",
        "        compress_between (float): Compression/stretch factor for 120 <= x <= 130 (default: 2.0)\n",
        "        compress_after (float): Compression factor for x > 130 (default: 0.5)\n",
        "\n",
        "    Returns:\n",
        "        float: Transformed value of x according to the specified compression rules\n",
        "\n",
        "    Behavior:\n",
        "        - For x < 120: applies compress_before multiplier (compression if < 1.0)\n",
        "        - For 120-130: applies compress_between multiplier (stretches if > 1.0)\n",
        "        - For x > 130: applies compress_after multiplier (compression if < 1.0)\n",
        "    \"\"\"\n",
        "    if x < 120:\n",
        "        return x * compress_before  # Compress region before 120 km\n",
        "    elif 120 <= x <= 130:\n",
        "        return 120 * compress_before + (x - 120) * compress_between  # Transform 120-130 km region\n",
        "    else:\n",
        "        return (120 * compress_before + 10 * compress_between) + (x - 130) * compress_after  # Compress region after 130 km"
      ],
      "metadata": {
        "id": "wJ8ZrPHItSt6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "documentation"
      ],
      "metadata": {
        "id": "_cfS8xoQvtvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CSFrFaVftfuV",
        "outputId": "416fc150-fe5d-4a2d-a3cd-7e773754312d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d12aee054c56>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Extract components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mnum_clusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/algorithms/components/connected.py\u001b[0m in \u001b[0;36mconnected_components\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_plain_bfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/networkx/algorithms/components/connected.py\u001b[0m in \u001b[0;36m_plain_bfs\u001b[0;34m(G, n, source)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mnextlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- Language translation: 'en' or 'ru' ---\n",
        "def tr(en_text: str, ru_text: str) -> str:\n",
        "    \"\"\"Simple translator function. Returns text based on current LANGUAGE setting.\"\"\"\n",
        "    return ru_text if LANGUAGE == 'ru' else en_text\n",
        "\n",
        "# --- Load volcano and earthquake coordinates ---\n",
        "\n",
        "# Function to parse coordinate strings\n",
        "# Helper to process \"Point(lon lat)\" format to (lat, lon)\n",
        "def parse_coords(coord_string):\n",
        "    lon, lat = map(float, coord_string.replace(\"Point(\", \"\").replace(\")\", \"\").split())\n",
        "    return (lat, lon)\n",
        "\n",
        "# === Bipartite Graph Clustering: Volcanoes and Earthquakes ===\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# --- Load coordinates ---\n",
        "def parse_coords(coord_string):\n",
        "    lon, lat = map(float, coord_string.replace(\"Point(\", \"\").replace(\")\", \"\").split())\n",
        "    return (lat, lon)\n",
        "\n",
        "volcano_coords = []\n",
        "earthquake_coords = []\n",
        "\n",
        "with open(\"volcanoes_2023.csv\", encoding='utf-8', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter=\";\")\n",
        "    for row in reader:\n",
        "        volcano_coords.append(parse_coords(row['location']))\n",
        "\n",
        "with open(\"earthquakes_2023.csv\", encoding='utf-8', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter=\";\")\n",
        "    for row in reader:\n",
        "        earthquake_coords.append(parse_coords(row['location']))\n",
        "\n",
        "# --- Create all pairs and distances ---\n",
        "volcano_indices = list(range(len(volcano_coords)))\n",
        "earthquake_indices = list(range(len(earthquake_coords)))\n",
        "\n",
        "pairs = []  # (distance, v_idx, e_idx)\n",
        "\n",
        "for vi in volcano_indices:\n",
        "    for ei in earthquake_indices:\n",
        "        dist = geodesic(volcano_coords[vi], earthquake_coords[ei]).km\n",
        "        pairs.append((dist, vi, ei))\n",
        "\n",
        "pairs.sort()  # Sort by distance\n",
        "\n",
        "# --- Bipartite clustering ---\n",
        "class UnionFind:\n",
        "    def __init__(self, n):\n",
        "        self.parent = list(range(n))\n",
        "\n",
        "    def find(self, x):\n",
        "        if self.parent[x] != x:\n",
        "            self.parent[x] = self.find(self.parent[x])\n",
        "        return self.parent[x]\n",
        "\n",
        "    def union(self, x, y):\n",
        "        rx, ry = self.find(x), self.find(y)\n",
        "        if rx != ry:\n",
        "            self.parent[ry] = rx\n",
        "\n",
        "# Assign global indices to nodes\n",
        "offset = len(volcano_coords)\n",
        "total_nodes = offset + len(earthquake_coords)\n",
        "\n",
        "uf = UnionFind(total_nodes)\n",
        "\n",
        "distances = []\n",
        "num_clusters = []\n",
        "avg_cluster_sizes = []\n",
        "largest_cluster_sizes = []\n",
        "largest_diameters = []\n",
        "\n",
        "volcano_only = []\n",
        "earthquake_only = []\n",
        "mixed_groups = []\n",
        "\n",
        "G = nx.Graph()\n",
        "for i in range(total_nodes):\n",
        "    G.add_node(i)\n",
        "\n",
        "for step, (d, vi, ei) in enumerate(pairs):\n",
        "    v_global = vi\n",
        "    e_global = ei + offset\n",
        "\n",
        "    if uf.find(v_global) != uf.find(e_global):\n",
        "        uf.union(v_global, e_global)\n",
        "        G.add_edge(v_global, e_global)\n",
        "\n",
        "        # Extract components\n",
        "        components = list(nx.connected_components(G))\n",
        "        distances.append(d)\n",
        "        num_clusters.append(len(components))\n",
        "\n",
        "        sizes = [len(c) for c in components]\n",
        "        avg_cluster_sizes.append(np.mean(sizes))\n",
        "        largest_cluster_sizes.append(max(sizes))\n",
        "\n",
        "        # Diameter of largest cluster\n",
        "        largest = max(components, key=len)\n",
        "        coords = []\n",
        "        for idx in largest:\n",
        "            if idx < offset:\n",
        "                coords.append(volcano_coords[idx])\n",
        "            else:\n",
        "                coords.append(earthquake_coords[idx - offset])\n",
        "\n",
        "        max_diam = 0\n",
        "        for i in range(len(coords)):\n",
        "            for j in range(i+1, len(coords)):\n",
        "                d_ij = geodesic(coords[i], coords[j]).km\n",
        "                if d_ij > max_diam:\n",
        "                    max_diam = d_ij\n",
        "        largest_diameters.append(max_diam)\n",
        "\n",
        "        # Count cluster types\n",
        "        v_only, e_only, mixed = 0, 0, 0\n",
        "        for comp in components:\n",
        "            types = {\"volcano\" if idx < offset else \"earthquake\" for idx in comp}\n",
        "            if types == {\"volcano\"}:\n",
        "                v_only += 1\n",
        "            elif types == {\"earthquake\"}:\n",
        "                e_only += 1\n",
        "            else:\n",
        "                mixed += 1\n",
        "        volcano_only.append(v_only)\n",
        "        earthquake_only.append(e_only)\n",
        "        mixed_groups.append(mixed)\n",
        "\n",
        "# --- Plotting ---\n",
        "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "ax1.plot(distances, num_clusters, label=\"Number of Clusters\", color=\"blue\")\n",
        "ax1.plot(distances, largest_cluster_sizes, label=\"Largest Cluster Size\", color=\"orange\")\n",
        "ax1.plot(distances, avg_cluster_sizes, label=\"Average Cluster Size\", color=\"red\", linestyle=\"--\")\n",
        "\n",
        "ax2.plot(distances, largest_diameters, label=\"Largest Cluster Diameter (km)\", color=\"green\", linestyle=\"-.\")\n",
        "\n",
        "ax1.set_xlabel(\"Minimum Distance in Bipartite Graph (km)\", fontsize=14)\n",
        "ax1.set_ylabel(\"Group Size Metrics\", fontsize=14)\n",
        "ax2.set_ylabel(\"Diameter (km)\", fontsize=14, color='green')\n",
        "ax2.tick_params(axis='y', colors='green')\n",
        "\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
        "\n",
        "plt.title(\"Bipartite Volcano-Earthquake Clustering by Distance\", fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Second plot: composition of groups ---\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.plot(distances, volcano_only, label=\"Volcano-only Groups\", linestyle='--', marker='^', color='red')\n",
        "ax.plot(distances, earthquake_only, label=\"Earthquake-only Groups\", linestyle='dashed', marker='v', color='black')\n",
        "ax.plot(distances, mixed_groups, label=\"Mixed Groups\", linestyle='-', marker='o', color='green', linewidth=2.5)\n",
        "\n",
        "ax.set_xlabel(\"Minimum Distance in Bipartite Graph (km)\", fontsize=14)\n",
        "ax.set_ylabel(\"Number of Groups by Type\", fontsize=14)\n",
        "ax.legend(loc=\"upper right\")\n",
        "plt.title(\"Cluster Type Breakdown in Bipartite Graph\", fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌍 Cluster Visualization on the Map (dist_max = 90 km)\n",
        "\n",
        "This code visualizes the spatial clustering of volcanoes and earthquakes using a distance threshold of 90 km.\n",
        "Each cluster is drawn as a circle whose radius covers all its points (computed by the most distant pair).\n",
        "We distinguish three cluster types:\n",
        "\n",
        "    🔴 Volcano-only clusters: red circles\n",
        "\n",
        "    ⚫ Earthquake-only clusters: black circles\n",
        "\n",
        "    🟢 Mixed clusters (both volcanoes and earthquakes): green dashed circles\n",
        "\n",
        "The cluster center is calculated using the midpoint between the two most distant points in the group, ensuring the circle encloses the entire cluster.\n",
        "\n",
        "This visualization provides geographic insight into the structure and composition of natural hazard clusters across the globe."
      ],
      "metadata": {
        "id": "R_ArijZyhHTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === VISUALIZE CLUSTERS ON MAP FOR dist_max = 90 ===\n",
        "\n",
        "# Build graph for dist_max = 90\n",
        "G90 = nx.Graph()\n",
        "for idx, coord in enumerate(all_coords):\n",
        "    G90.add_node(idx, pos=coord, type=types[idx])\n",
        "    indices = tree.query_ball_point(np.radians(coord), r=90/6371.0)\n",
        "    for neighbor_idx in indices:\n",
        "        if neighbor_idx != idx:\n",
        "            G90.add_edge(idx, neighbor_idx)\n",
        "\n",
        "# Find connected components\n",
        "components_90 = list(nx.connected_components(G90))\n",
        "\n",
        "# Create map centered around mean location\n",
        "center_latlon = compute_center(all_coords)\n",
        "m = folium.Map(location=center_latlon, zoom_start=2)\n",
        "\n",
        "# Loop through each group and classify\n",
        "for group in components_90:\n",
        "    coords = [all_coords[idx] for idx in group]\n",
        "    group_types = {types[idx] for idx in group}\n",
        "    color = \"blue\"\n",
        "    fill = False\n",
        "    dash = False\n",
        "\n",
        "    if group_types == {\"volcano\"}:\n",
        "        color = \"red\"\n",
        "        dash = False\n",
        "    elif group_types == {\"earthquake\"}:\n",
        "        color = \"black\"\n",
        "        dash = False\n",
        "    else:\n",
        "        color = \"green\"\n",
        "        dash = True\n",
        "\n",
        "    center = compute_center_by_farthest_pair(coords)\n",
        "    diameter = compute_group_diameter(coords)\n",
        "\n",
        "    folium.Circle(\n",
        "        location=center,\n",
        "        radius=(diameter / 2) * 1000,\n",
        "        color=color,\n",
        "        fill=fill,\n",
        "        dash_array=\"5,5\" if dash else None,\n",
        "        weight=2,\n",
        "        opacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "# Show the map\n",
        "m"
      ],
      "metadata": {
        "id": "0PTRFAGRqRJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Анализ объединения групп при dist_max=127 и dist_max=128\n",
        "# Analyzing group merging at dist_max=127 and dist_max=128\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from scipy.spatial import KDTree\n",
        "\n",
        "# Search parameters\n",
        "dist_min = 127\n",
        "dist_max = 128\n",
        "\n",
        "# Using pre-defined volcano_coords and earthquake_coords\n",
        "all_coords = volcano_coords + earthquake_coords\n",
        "types = ['volcano'] * len(volcano_coords) + ['earthquake'] * len(earthquake_coords)\n",
        "\n",
        "# Building KD-tree for neighbor search\n",
        "tree = KDTree(np.radians(all_coords))\n",
        "\n",
        "# Function to build graph with given distance threshold\n",
        "def build_graph(coords, dist_threshold_km):\n",
        "    G = nx.Graph()\n",
        "    for idx, coord in enumerate(coords):\n",
        "        G.add_node(idx, pos=coord, type=types[idx])\n",
        "        neighbors = tree.query_ball_point(np.radians(coord), r=dist_threshold_km/6371.0)\n",
        "        for neighbor in neighbors:\n",
        "            if neighbor != idx:\n",
        "                G.add_edge(idx, neighbor)\n",
        "    return G\n",
        "\n",
        "# Build graphs for dist_max=127 and 128\n",
        "G_127 = build_graph(all_coords, dist_min)\n",
        "G_128 = build_graph(all_coords, dist_max)\n",
        "\n",
        "# Get connected components (group lists)\n",
        "groups_127 = list(nx.connected_components(G_127))\n",
        "groups_128 = list(nx.connected_components(G_128))\n",
        "\n",
        "print(f\"Number of groups at {dist_min} km: {len(groups_127)}\")\n",
        "print(f\"Number of groups at {dist_max} km: {len(groups_128)}\")\n",
        "\n",
        "# Create mapping: which group at 128km each point belongs to\n",
        "node_to_group_128 = {}\n",
        "for idx, group in enumerate(groups_128):\n",
        "    for node in group:\n",
        "        node_to_group_128[node] = idx\n",
        "\n",
        "# Analyze groups at 127 km\n",
        "# Check how many different 127km groups fall into the same 128km group\n",
        "\n",
        "merged_groups = []\n",
        "\n",
        "for group in groups_127:\n",
        "    parent_groups = set(node_to_group_128[node] for node in group)\n",
        "    if len(parent_groups) > 1:\n",
        "        continue\n",
        "    parent_group = next(iter(parent_groups))\n",
        "    if len([g for g in groups_127 if any(node_to_group_128[n] == parent_group for n in g)]) > 1:\n",
        "        merged_groups.append(group)\n",
        "\n",
        "print(f\"Number of merged groups: {len(merged_groups)}\")\n",
        "\n",
        "# Print group sizes\n",
        "print(\"\\nMerged Groups (sorted by size):\")\n",
        "merged_groups_sorted = sorted(merged_groups, key=lambda g: -len(g))\n",
        "for i, g in enumerate(merged_groups_sorted):\n",
        "    volcanoes = sum(1 for n in g if types[n] == 'volcano')\n",
        "    earthquakes = sum(1 for n in g if types[n] == 'earthquake')\n",
        "    print(f\"Group {i+1}: Size = {len(g)} (Volcanoes: {volcanoes}, Earthquakes: {earthquakes})\")\n",
        "\n",
        "# Save found groups for future visualization\n",
        "merged_groups_for_viz = merged_groups_sorted"
      ],
      "metadata": {
        "id": "eShlbrgc8oXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📍 Computing the Center Based on the Farthest Pair\n",
        "\n",
        "The function `compute_center_by_farthest_pair(group_coords)` finds the two most distant points in a group and calculates the geographic midpoint between them.\n",
        "\n",
        "**Main idea:**\n",
        "- Iterate through all point pairs to find the maximum geodesic distance.\n",
        "- Take the midpoint between the two farthest points.\n",
        "- Use this midpoint as a more accurate center for drawing coverage circles.\n",
        "\n",
        "✨ This method ensures that at least the most distant points are well-centered inside the circle.\n",
        "\n",
        "---\n",
        "\n",
        "# 📍 Вычисление центра на основе самой удалённой пары точек\n",
        "\n",
        "Функция `compute_center_by_farthest_pair(group_coords)` находит две наиболее удалённые точки в группе и вычисляет географический центр между ними.\n",
        "\n",
        "**Основная идея:**\n",
        "- Перебрать все пары точек и найти пару с максимальным геодезическим расстоянием.\n",
        "- Вычислить середину между двумя самыми удалёнными точками.\n",
        "- Использовать эту середину как более точный центр для построения круга охвата.\n",
        "\n",
        "✨ Этот метод гарантирует, что хотя бы самые удалённые точки окажутся внутри построенного круга."
      ],
      "metadata": {
        "id": "4NiKBIJPdVqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_center_by_farthest_pair(group_coords):\n",
        "    max_distance = 0\n",
        "    farthest_pair = (0, 0)\n",
        "    n = len(group_coords)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            d = geodesic(group_coords[i], group_coords[j]).km\n",
        "            if d > max_distance:\n",
        "                max_distance = d\n",
        "                farthest_pair = (i, j)\n",
        "    # Midpoint between two farthest points\n",
        "    lat1, lon1 = group_coords[farthest_pair[0]]\n",
        "    lat2, lon2 = group_coords[farthest_pair[1]]\n",
        "    center_lat = (lat1 + lat2) / 2\n",
        "    center_lon = (lon1 + lon2) / 2\n",
        "    return (center_lat, center_lon)\n",
        "\n",
        "\n",
        "# Helper to compute center of a group (average coordinates)\n",
        "def compute_center(coords):\n",
        "    latitudes = [c[0] for c in coords]\n",
        "    longitudes = [c[1] for c in coords]\n",
        "    return np.mean(latitudes), np.mean(longitudes)"
      ],
      "metadata": {
        "id": "FRHSij-Cdb3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📜 Жадное покрытие группы кругами с максимальным охватом (Greedy Covering with Maximum Coverage) 🗺️\n",
        "\n",
        "## 🇷🇺 Описание на русском:\n",
        "\n",
        "Функция `draw_cover_circles_greedy` реализует улучшенный жадный алгоритм покрытия группы кругами:\n",
        "\n",
        "**Основная идея:**\n",
        "- На каждом шаге выбирается та вершина, которая покрывает наибольшее количество ещё непокрытых вершин.\n",
        "- Строится окружность радиусом `dist_max` вокруг этой вершины.\n",
        "- Все попавшие в окружность вершины удаляются из рассмотрения.\n",
        "- Процесс повторяется, пока все вершины не будут покрыты.\n",
        "\n",
        "✨ Это минимизирует общее число кругов и позволяет сохранить карту более чистой и понятной.\n",
        "\n",
        "---\n",
        "\n",
        "## 🇬🇧 Description in English:\n",
        "\n",
        "The function `draw_cover_circles_greedy` implements an improved greedy algorithm for group covering with circles:\n",
        "\n",
        "**Main idea:**\n",
        "- At each step, select the node that covers the maximum number of uncovered points.\n",
        "- Draw a circle with radius `dist_max` around the selected node.\n",
        "- Remove all points inside the circle from the list.\n",
        "- Repeat until all nodes are covered.\n",
        "\n",
        "✨ This minimizes the total number of circles and keeps the map clean and readable."
      ],
      "metadata": {
        "id": "Om_6UX385axT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Greedy covering: select the most effective center at each step\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "def draw_cover_circles_greedy_effective(group_nodes, group_coords, color, dist_max_km, map_obj, dashed=False):\n",
        "    remaining_nodes = set(range(len(group_nodes)))\n",
        "    used_nodes = set()\n",
        "    dist_threshold = dist_max_km  # maximum allowed distance (radius)\n",
        "\n",
        "    while remaining_nodes:\n",
        "        best_idx = None\n",
        "        best_coverage = set()\n",
        "\n",
        "        for idx in remaining_nodes:\n",
        "            center_coord = group_coords[idx]\n",
        "            covered = set()\n",
        "            for j in remaining_nodes:\n",
        "                if idx != j:\n",
        "                    d = geodesic(center_coord, group_coords[j]).km\n",
        "                    if d <= dist_threshold:\n",
        "                        covered.add(j)\n",
        "            # Always include the center itself\n",
        "            covered.add(idx)\n",
        "\n",
        "            if len(covered) > len(best_coverage):\n",
        "                best_idx = idx\n",
        "                best_coverage = covered\n",
        "\n",
        "        # Draw the circle around the best node\n",
        "        center_coord = group_coords[best_idx]\n",
        "        folium.Circle(\n",
        "            location=center_coord,\n",
        "            radius=dist_max_km * 1000,  # meters\n",
        "            color=color,\n",
        "            fill=False,\n",
        "            weight=2,\n",
        "            opacity=0.7,\n",
        "            dash_array=\"5,5\" if dashed else None\n",
        "        ).add_to(map_obj)\n",
        "\n",
        "        # Remove covered nodes from the set\n",
        "        remaining_nodes -= best_coverage\n",
        "        used_nodes.add(best_idx)"
      ],
      "metadata": {
        "id": "s5O7_oBf5fkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🗺️ **Map of Merged Volcano and Earthquake Groups** 🌋⚡\n",
        "\n",
        "This map shows two largest groups that merged when the distance threshold changed from 127 km to 128 km:\n",
        "- 🔴 Red dots: Volcanoes\n",
        "- ⚫ Black dots: Earthquakes\n",
        "\n",
        "# 📜 Visualization of Volcano-Earthquake Groups with MST 🌋🌎\n",
        "\n",
        "This cell visualizes the two largest merged groups using Minimum Spanning Trees (MST).  \n",
        "Main features:\n",
        "- Volcanoes and earthquakes are shown with different colors and shapes.\n",
        "- MST edges are colored differently for Group 1 and Group 2.\n",
        "- Solid lines for Group 1, dashed lines for Group 2 for better black-and-white printing.\n",
        "- Thicker edges connect volcanoes and earthquakes.\n",
        "- A coverage circle of 127 km radius is drawn around each group.\n",
        "- Smaller and semi-transparent points are used to reduce clutter.\n",
        "\n",
        "✨ An interactive legend explains the colors, symbols, and lines."
      ],
      "metadata": {
        "id": "Etp23UniDRP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Select two largest groups\n",
        "group1 = list(merged_groups_for_viz[0])\n",
        "group2 = list(merged_groups_for_viz[1])\n",
        "\n",
        "# Helper function to build MST for a group\n",
        "def build_mst(group_nodes):\n",
        "    coords = [all_coords[idx] for idx in group_nodes]\n",
        "    G = nx.Graph()\n",
        "    for i in range(len(coords)):\n",
        "        for j in range(i+1, len(coords)):\n",
        "            dist = geodesic(coords[i], coords[j]).km\n",
        "            G.add_edge(i, j, weight=dist)\n",
        "    mst = nx.minimum_spanning_tree(G)\n",
        "    return mst, coords\n",
        "\n",
        "# Build MSTs\n",
        "mst1, coords1 = build_mst(group1)\n",
        "mst2, coords2 = build_mst(group2)\n",
        "\n",
        "center1 = compute_center(coords1)\n",
        "center2 = compute_center(coords2)\n",
        "\n",
        "# Create the map\n",
        "m = folium.Map(location=center1, zoom_start=3)\n",
        "\n",
        "# Draw MST for Group 1\n",
        "for edge in mst1.edges():\n",
        "    idx1, idx2 = edge\n",
        "    coord1 = coords1[idx1]\n",
        "    coord2 = coords1[idx2]\n",
        "    node1 = group1[idx1]\n",
        "    node2 = group1[idx2]\n",
        "    is_mixed = (types[node1] != types[node2])\n",
        "    folium.PolyLine(\n",
        "        locations=[coord1, coord2],\n",
        "        color=\"purple\",\n",
        "        weight=4 if is_mixed else 2,\n",
        "        opacity=1,\n",
        "        dash_array=None\n",
        "    ).add_to(m)\n",
        "\n",
        "# Draw MST for Group 2\n",
        "for edge in mst2.edges():\n",
        "    idx1, idx2 = edge\n",
        "    coord1 = coords2[idx1]\n",
        "    coord2 = coords2[idx2]\n",
        "    node1 = group2[idx1]\n",
        "    node2 = group2[idx2]\n",
        "    is_mixed = (types[node1] != types[node2])\n",
        "    folium.PolyLine(\n",
        "        locations=[coord1, coord2],\n",
        "        color=\"green\",\n",
        "        weight=4 if is_mixed else 2,\n",
        "        opacity=1,\n",
        "        dash_array=\"5,5\"\n",
        "    ).add_to(m)\n",
        "\n",
        "# Draw points for Group 1\n",
        "degree_count1 = dict(mst1.degree())\n",
        "for idx, coord in enumerate(coords1):\n",
        "    node = group1[idx]\n",
        "  # size = 4 if degree_count1[idx] == 1 else 7\n",
        "    size = 1 if degree_count1[idx] == 1 else 3\n",
        "    color = \"red\" if types[node] == \"volcano\" else \"black\"\n",
        "    folium.CircleMarker(\n",
        "        location=coord,\n",
        "        radius=size,\n",
        "        color=color,\n",
        "        fill=True,\n",
        "        fill_color=color,\n",
        "        fill_opacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "# Draw points for Group 2\n",
        "degree_count2 = dict(mst2.degree())\n",
        "for idx, coord in enumerate(coords2):\n",
        "    node = group2[idx]\n",
        "#   size = 4 if degree_count2[idx] == 1 else 7\n",
        "    size = 1 if degree_count1[idx] == 1 else 3\n",
        "    color = \"#FFA07A\" if types[node] == \"volcano\" else \"#2F4F4F\"\n",
        "    folium.RegularPolygonMarker(\n",
        "        location=coord,\n",
        "        number_of_sides=5 if types[node] == \"volcano\" else 4,\n",
        "        radius=size,\n",
        "        color=color,\n",
        "        fill=True,\n",
        "        fill_color=color,\n",
        "        fill_opacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "\n",
        "# Compute diameters\n",
        "diameter1 = compute_group_diameter(coords1)\n",
        "diameter2 = compute_group_diameter(coords2)\n",
        "\n",
        "print(f\"Diameter of Group 1: {diameter1:.2f} km\")\n",
        "print(f\"Diameter of Group 2: {diameter2:.2f} km\")\n",
        "\n",
        "\n",
        "\n",
        "# Compute better centers for Group 1 and Group 2\n",
        "center1_better = compute_center_by_farthest_pair(coords1)\n",
        "center2_better = compute_center_by_farthest_pair(coords2)\n",
        "\n",
        "# Draw big circles with improved centers\n",
        "folium.Circle(\n",
        "    location=center1_better,\n",
        "    radius=(diameter1 / 2) * 1000,  # meters\n",
        "    color=\"purple\",\n",
        "    fill=False,\n",
        "    weight=3,\n",
        "    opacity=0.5\n",
        ").add_to(m)\n",
        "\n",
        "folium.Circle(\n",
        "    location=center2_better,\n",
        "    radius=(diameter2 / 2) * 1000,\n",
        "    color=\"green\",\n",
        "    fill=False,\n",
        "    dash_array=\"5,5\",\n",
        "    weight=3,\n",
        "    opacity=0.5\n",
        ").add_to(m)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Greedy Covering with Circles - алгоритм \"жадного покрытия группы кругами\"\n",
        "draw_cover_circles_greedy_effective(group1, coords1, color=\"purple\", dist_max_km=127, map_obj=m, dashed=False)\n",
        "draw_cover_circles_greedy_effective(group2, coords2, color=\"green\", dist_max_km=127, map_obj=m, dashed=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Add legend\n",
        "# legend_html = '''\n",
        "# <div style=\"position: fixed;\n",
        "#      bottom: 550px; left: 250px;\n",
        "#      background-color: white;\n",
        "#      border:2px solid grey; z-index:9999; font-size:14px;\n",
        "#      padding-bottom: 3px; padding-right: 4px;\">\n",
        "#           &nbsp;<b>Legend</b><br>\n",
        "#           &nbsp;<span style=\"color:red;\">● Volcano (Group 1)</span><br>\n",
        "#           &nbsp;<span style=\"color:black;\">● Earthquake (Group 1)</span><br>\n",
        "#           &nbsp;<span style=\"color:#FFA07A;\">⬠ Volcano (Group 2)</span><br>\n",
        "#           &nbsp;<span style=\"color:#2F4F4F;\">■ Earthquake (Group 2)</span><br>\n",
        "#           &nbsp;<span style=\"color:purple;\">━ MST Edge (Group 1)</span><br>\n",
        "#           &nbsp;<span style=\"color:green;\">━ MST Edge Dashed (Group 2)</span>\n",
        "# </div>\n",
        "# '''\n",
        "\n",
        "# Add legend with Russian text\n",
        "legend_html = '''\n",
        "<div style=\"position: fixed;\n",
        "     bottom: 550px; left: 250px;\n",
        "     background-color: white;\n",
        "     border:2px solid grey; z-index:9999; font-size:14px;\n",
        "     padding-bottom: 3px; padding-right: 4px;\">\n",
        "     &nbsp;<b>Легенда</b><br>\n",
        "     &nbsp;<span style=\"color:purple;\">━ Группа 1</span><br>\n",
        "     &nbsp;&nbsp;&nbsp;<span style=\"color:red;\">● Вулкан</span><br>\n",
        "     &nbsp;&nbsp;&nbsp;<span style=\"color:black;\">● Землетрясение</span><br>\n",
        "     &nbsp;<span style=\"color:green;\">━ Группа 2, пунктир</span><br>\n",
        "     &nbsp;&nbsp;&nbsp;<span style=\"color:#FFA07A;\">⬠ Вулкан</span><br>\n",
        "     &nbsp;&nbsp;&nbsp;<span style=\"color:#2F4F4F;\">■ Землетрясение</span><br>\n",
        "</div>\n",
        "'''\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "metadata": {
        "id": "G5t-clggBUcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "пересчёт координат и построения графика\n"
      ],
      "metadata": {
        "id": "7BgKNgewkEvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📜 поиск локального изгиба через вторую производную"
      ],
      "metadata": {
        "id": "FQ0w48ZEMBdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume distances_max_list and groups_count_list are already calculated\n",
        "\n",
        "# Convert lists to numpy arrays for easier processing\n",
        "x = np.array(distances_max_list)\n",
        "y = np.array(groups_count_list)\n",
        "\n",
        "# Compute first derivative (differences)\n",
        "dy_dx = np.gradient(y, x)\n",
        "\n",
        "# Compute second derivative\n",
        "d2y_dx2 = np.gradient(dy_dx, x)\n",
        "\n",
        "# Find index of maximum absolute second derivative (largest curvature)\n",
        "elbow_idx = np.argmax(np.abs(d2y_dx2))\n",
        "elbow_dist = x[elbow_idx]\n",
        "\n",
        "print(f\"Elbow point detected at dist_max ≈ {elbow_dist} km using second derivative method.\")\n",
        "\n",
        "# --- Optionally, plot second derivative curve to visualize\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(x, d2y_dx2, marker='o')\n",
        "plt.axvline(x=elbow_dist, color='red', linestyle='--', label=f\"Elbow at {elbow_dist} km\")\n",
        "plt.title(\"Second Derivative of Group Count Curve\")\n",
        "plt.xlabel(\"Maximum Distance (km)\")\n",
        "plt.ylabel(\"Second Derivative (curvature)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fMD1ASoaMCik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}